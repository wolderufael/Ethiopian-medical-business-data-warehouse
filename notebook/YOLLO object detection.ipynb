{"cells":[{"cell_type":"markdown","metadata":{"id":"uFuxiQgQHiii"},"source":["# Object Detection using YOLO model"]},{"cell_type":"markdown","metadata":{},"source":["To enhance the data analysis capabilities of the data warehouse, we employed a pre-trained YOLO model to identify medical equipment within the scraped images. YOLO, a state-of-the-art object detection algorithm, is particularly well-suited for real-time applications and offers high accuracy."]},{"cell_type":"markdown","metadata":{"id":"UFDJfUnxHqyw"},"source":["### Mount google drive"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":40206,"status":"ok","timestamp":1729014696009,"user":{"displayName":"Wolderufael Kassahun","userId":"05849674619156846485"},"user_tz":-180},"id":"bKIwzpSuFRfC","outputId":"1117828d-ff3b-4f93-f873-ad6313fabe72"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"uKlEV-55HxrP"},"source":["### Change directory to my folder"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5u7JmyrKFVzS"},"outputs":[],"source":["import os\n","os.chdir('/content/drive/My Drive/Kifiya_AI_mastery_10_Academy/Week07/YOLO')"]},{"cell_type":"markdown","metadata":{"id":"0eHh6BZcH-Zv"},"source":["## Clone YOLO repository"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5343,"status":"ok","timestamp":1728977583738,"user":{"displayName":"Wolderufael Kassahun","userId":"05849674619156846485"},"user_tz":-180},"id":"i9JGUA_F-IUw","outputId":"a47e3389-2b55-4ae6-ccdf-c96d5e6bf033"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'yolov5'...\n","remote: Enumerating objects: 16982, done.\u001b[K\n","remote: Counting objects: 100% (177/177), done.\u001b[K\n","remote: Compressing objects: 100% (124/124), done.\u001b[K\n","remote: Total 16982 (delta 92), reused 110 (delta 53), pack-reused 16805 (from 1)\u001b[K\n","Receiving objects: 100% (16982/16982), 15.72 MiB | 15.40 MiB/s, done.\n","Resolving deltas: 100% (11625/11625), done.\n"]}],"source":["!git clone https://github.com/ultralytics/yolov5.git"]},{"cell_type":"markdown","metadata":{"id":"wdqZc9k0IIic"},"source":["### Install dependecies"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":6151,"status":"ok","timestamp":1729014711227,"user":{"displayName":"Wolderufael Kassahun","userId":"05849674619156846485"},"user_tz":-180},"id":"wd1FPev--ODt","outputId":"93607495-8dd6-4deb-e3cf-ce0f2fc9c15b"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/My Drive/Kifiya_AI_mastery_10_Academy/Week07/YOLO/yolov5\n","Collecting gitpython>=3.1.30 (from -r requirements.txt (line 5))\n","  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (3.7.1)\n","Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (1.26.4)\n","Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (4.10.0.84)\n","Requirement already satisfied: pillow>=10.3.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (10.4.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (5.9.5)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (6.0.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (2.32.3)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (1.13.1)\n","Collecting thop>=0.1.1 (from -r requirements.txt (line 14))\n","  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (2.4.1+cu121)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (0.19.1+cu121)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (4.66.5)\n","Collecting ultralytics>=8.2.34 (from -r requirements.txt (line 18))\n","  Downloading ultralytics-8.3.13-py3-none-any.whl.metadata (34 kB)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 27)) (2.2.2)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 28)) (0.13.2)\n","Requirement already satisfied: setuptools>=70.0.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 42)) (71.0.4)\n","Collecting gitdb<5,>=4.0.1 (from gitpython>=3.1.30->-r requirements.txt (line 5))\n","  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.3.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (4.54.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.4.7)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (24.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (3.1.4)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (2.8.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (2024.8.30)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.4)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2024.6.1)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics>=8.2.34->-r requirements.txt (line 18)) (9.0.0)\n","Collecting ultralytics-thop>=2.0.0 (from ultralytics>=8.2.34->-r requirements.txt (line 18))\n","  Downloading ultralytics_thop-2.0.9-py3-none-any.whl.metadata (9.3 kB)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2024.2)\n","Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r requirements.txt (line 5))\n","  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r requirements.txt (line 6)) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->-r requirements.txt (line 15)) (3.0.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->-r requirements.txt (line 15)) (1.3.0)\n","Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n","Downloading ultralytics-8.3.13-py3-none-any.whl (870 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m870.5/870.5 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ultralytics_thop-2.0.9-py3-none-any.whl (26 kB)\n","Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n","Installing collected packages: smmap, gitdb, ultralytics-thop, thop, gitpython, ultralytics\n","Successfully installed gitdb-4.0.11 gitpython-3.1.43 smmap-5.0.1 thop-0.1.1.post2209072238 ultralytics-8.3.13 ultralytics-thop-2.0.9\n"]}],"source":["%cd yolov5/\n","!pip install -r requirements.txt\n"]},{"cell_type":"markdown","metadata":{},"source":["# Object Detection with YOLOv5\n","\n","This script performs object detection on a set of images using the YOLOv5 model. The detected results, which include bounding boxes drawn around detected objects, are saved to a specified output directory.\n","\n","## Overview of the Code\n","\n","1. **Import Libraries**: \n","   - `torch`: For loading the YOLOv5 model.\n","   - `cv2`: For image reading and writing operations.\n","   - `os`: For handling file and directory operations.\n","\n","2. **Load the YOLOv5 Model**: \n","   - The pre-trained YOLOv5 model (`yolov5s`) is loaded using `torch.hub.load`. This model is lightweight and suitable for real-time object detection tasks.\n","\n","3. **Set Paths**:\n","   - `image_folder`: Path to the directory containing images that need to be processed.\n","   - `output_folder`: Path to the directory where the detection results will be saved.\n","\n","4. **Create Output Directory**: \n","   - If the output folder does not exist, it is created using `os.makedirs`.\n","\n","5. **Loop Through Images**: \n","   - The script iterates through each image in the specified `image_folder`.\n","   - Each image is read using OpenCV's `cv2.imread`.\n","\n","6. **Check for Image Validity**: \n","   - If an image cannot be read (i.e., `img` is `None`), a message is printed, and the script continues to the next image.\n","\n","7. **Run Object Detection**: \n","   - The model processes the image and detects objects within it.\n","\n","8. **Render Results**: \n","   - Detected objects are drawn on the image using the `results.render()` method.\n","\n","9. **Save Detected Images**: \n","   - The modified image (with bounding boxes) is saved in the `output_folder` with the same name as the original image using `cv2.imwrite`.\n","\n","10. **Print Confirmation**: \n","    - A message is printed to indicate that the detection result for the image has been saved successfully.\n","\n","### Conclusion\n","\n","This script allows you to automate the process of object detection on multiple images, leveraging the capabilities of the YOLOv5 model. The output images can be used for further analysis or visualization of the detected objects.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1AG_uMlBa4aadq9emmiuuY_7r4XOYcxuE"},"id":"cABdHK_oLwUv","outputId":"2bb9e38e-2710-48c5-8e63-76799cbd2811"},"outputs":[{"data":{"text/plain":["Output hidden; open in https://colab.research.google.com to view."]},"metadata":{},"output_type":"display_data"}],"source":["import torch\n","import cv2\n","import os\n","\n","# Load pre-trained YOLOv5 model\n","model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n","\n","# Path to the directory containing the images\n","image_folder = '../Photo'\n","\n","# Output folder for detection results\n","output_folder = 'detection_results/'\n","\n","# Create the output folder if it doesn't exist\n","os.makedirs(output_folder, exist_ok=True)\n","\n","# Loop through the images in the folder and run object detection\n","for img_name in os.listdir(image_folder):\n","    img_path = os.path.join(image_folder, img_name)\n","\n","    # Read the image using OpenCV\n","    img = cv2.imread(img_path)\n","\n","    if img is None:\n","        print(f\"Could not read image {img_name}. Skipping...\")\n","        continue\n","\n","    # Run object detection\n","    results = model(img)\n","    results.show()\n","\n","    # Extract the results as an image (with bounding boxes)\n","    detected_img = results.render()[0]  # YOLOv5's `render` method draws the boxes on the image\n","\n","    # Save the detected image with the same name as the original image\n","    output_path = os.path.join(output_folder, img_name)\n","    cv2.imwrite(output_path, detected_img)\n","\n","    print(f\"Saved detection result for {img_name} to {output_folder}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["# Object Detection Results Processing\n","\n","This script processes the object detection results obtained from the YOLOv5 model and saves the data into a single CSV file. Each row in the CSV corresponds to a unique image, summarizing all detected objects for that image.\n","\n","## Overview of the Code\n","\n","1. **Import Libraries**:\n","   - `pandas`: For handling data in a DataFrame and saving it to CSV.\n","   - `os`: For interacting with the file system.\n","\n","2. **Initialize List for Detections**:\n","   - An empty list, `all_detections`, is created to store the detection results for each image.\n","\n","3. **Loop Through Images**:\n","   - The script iterates through each image in the specified `image_folder`.\n","\n","4. **Run Object Detection**:\n","   - For each image, the detection model is applied using `model(img_path)` to get detection results.\n","\n","5. **Extract Detection Data**:\n","   - The results are extracted into a Pandas DataFrame using `results.pandas().xyxy[0]`.\n","   - Various attributes of the detections (labels, confidence scores, bounding box coordinates) are extracted into separate lists:\n","     - `labels`: List of detected object labels.\n","     - `confidences`: List of confidence scores for each detection.\n","     - `xmins`, `ymins`, `xmaxs`, `ymaxs`: Lists of bounding box coordinates.\n","\n","6. **Append Detection Data**:\n","   - A dictionary containing the image name and the detection data is appended to the `all_detections` list.\n","   - The lists of labels, confidences, and coordinates are converted to comma-separated strings for easy storage in a single CSV row.\n","\n","7. **Create DataFrame**:\n","   - The list of dictionaries, `all_detections`, is converted into a Pandas DataFrame, `df_all_detections`.\n","\n","8. **Save to CSV**:\n","   - The DataFrame is saved to a CSV file named `all_detections_single_row.csv` in the `detection_results` directory, with no index included.\n","\n","9. **Print Confirmation**:\n","   - A message is printed to confirm that all detections have been saved successfully.\n","\n","### Conclusion\n","\n","This script consolidates the detection results from multiple images into a single CSV file, facilitating easier data analysis and review. Each row corresponds to a unique image, with detection details stored as comma-separated strings, making it convenient to load and analyze the data later.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XgzbAuQEkfgi"},"outputs":[],"source":["import pandas as pd\n","import os\n","\n","# Initialize an empty list to store all detection results for each image\n","all_detections = []\n","\n","# Loop through the images in the folder and process the detection results\n","for img_name in os.listdir(image_folder):\n","    img_path = os.path.join(image_folder, img_name)\n","\n","    # Run object detection\n","    results = model(img_path)\n","\n","    # Extract the detection data as a Pandas DataFrame\n","    detections = results.pandas().xyxy[0]  # Pandas DataFrame of detection results\n","\n","    # Extract details into lists\n","    labels = detections['name'].tolist()  # List of object labels\n","    confidences = detections['confidence'].tolist()  # List of confidence scores\n","    xmins = detections['xmin'].tolist()  # List of xmin values\n","    ymins = detections['ymin'].tolist()  # List of ymin values\n","    xmaxs = detections['xmax'].tolist()  # List of xmax values\n","    ymaxs = detections['ymax'].tolist()  # List of ymax values\n","\n","    # Append a single row of data for this image (lists of detections)\n","    all_detections.append({\n","        'image_name': img_name,\n","        'labels': ','.join(labels),  # Convert list to comma-separated string\n","        'confidences': ','.join(map(str, confidences)),  # Convert list of floats to string\n","        'xmins': ','.join(map(str, xmins)),\n","        'ymins': ','.join(map(str, ymins)),\n","        'xmaxs': ','.join(map(str, xmaxs)),\n","        'ymaxs': ','.join(map(str, ymaxs))\n","    })\n","\n","# Convert the list of dictionaries to a DataFrame\n","df_all_detections = pd.DataFrame(all_detections)\n","\n","# Save the DataFrame to a single CSV file\n","df_all_detections.to_csv('detection_results/all_detections_single_row.csv', index=False)\n","\n","print(\"All detections saved to 'detection_results/all_detection_results.csv'.\")\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1rEQXqrQu7nEJog3dp4-54tOqDendbHse","timestamp":1728976446224}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}

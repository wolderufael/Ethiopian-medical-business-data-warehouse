{"cells":[{"cell_type":"markdown","metadata":{"id":"uFuxiQgQHiii"},"source":["# Object Detection using YOLO model"]},{"cell_type":"markdown","metadata":{"id":"UFDJfUnxHqyw"},"source":["### Mount google drive"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":40206,"status":"ok","timestamp":1729014696009,"user":{"displayName":"Wolderufael Kassahun","userId":"05849674619156846485"},"user_tz":-180},"id":"bKIwzpSuFRfC","outputId":"1117828d-ff3b-4f93-f873-ad6313fabe72"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"uKlEV-55HxrP"},"source":["### Change directory to my folder"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5u7JmyrKFVzS"},"outputs":[],"source":["import os\n","os.chdir('/content/drive/My Drive/Kifiya_AI_mastery_10_Academy/Week07/YOLO')"]},{"cell_type":"markdown","metadata":{"id":"0eHh6BZcH-Zv"},"source":["## Clone YOLO repository"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5343,"status":"ok","timestamp":1728977583738,"user":{"displayName":"Wolderufael Kassahun","userId":"05849674619156846485"},"user_tz":-180},"id":"i9JGUA_F-IUw","outputId":"a47e3389-2b55-4ae6-ccdf-c96d5e6bf033"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'yolov5'...\n","remote: Enumerating objects: 16982, done.\u001b[K\n","remote: Counting objects: 100% (177/177), done.\u001b[K\n","remote: Compressing objects: 100% (124/124), done.\u001b[K\n","remote: Total 16982 (delta 92), reused 110 (delta 53), pack-reused 16805 (from 1)\u001b[K\n","Receiving objects: 100% (16982/16982), 15.72 MiB | 15.40 MiB/s, done.\n","Resolving deltas: 100% (11625/11625), done.\n"]}],"source":["!git clone https://github.com/ultralytics/yolov5.git"]},{"cell_type":"markdown","metadata":{"id":"wdqZc9k0IIic"},"source":["### Install dependecies"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":6151,"status":"ok","timestamp":1729014711227,"user":{"displayName":"Wolderufael Kassahun","userId":"05849674619156846485"},"user_tz":-180},"id":"wd1FPev--ODt","outputId":"93607495-8dd6-4deb-e3cf-ce0f2fc9c15b"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/My Drive/Kifiya_AI_mastery_10_Academy/Week07/YOLO/yolov5\n","Collecting gitpython>=3.1.30 (from -r requirements.txt (line 5))\n","  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (3.7.1)\n","Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (1.26.4)\n","Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (4.10.0.84)\n","Requirement already satisfied: pillow>=10.3.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (10.4.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (5.9.5)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (6.0.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (2.32.3)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (1.13.1)\n","Collecting thop>=0.1.1 (from -r requirements.txt (line 14))\n","  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (2.4.1+cu121)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (0.19.1+cu121)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (4.66.5)\n","Collecting ultralytics>=8.2.34 (from -r requirements.txt (line 18))\n","  Downloading ultralytics-8.3.13-py3-none-any.whl.metadata (34 kB)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 27)) (2.2.2)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 28)) (0.13.2)\n","Requirement already satisfied: setuptools>=70.0.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 42)) (71.0.4)\n","Collecting gitdb<5,>=4.0.1 (from gitpython>=3.1.30->-r requirements.txt (line 5))\n","  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.3.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (4.54.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.4.7)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (24.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (3.1.4)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (2.8.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (2024.8.30)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.4)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2024.6.1)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics>=8.2.34->-r requirements.txt (line 18)) (9.0.0)\n","Collecting ultralytics-thop>=2.0.0 (from ultralytics>=8.2.34->-r requirements.txt (line 18))\n","  Downloading ultralytics_thop-2.0.9-py3-none-any.whl.metadata (9.3 kB)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2024.2)\n","Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r requirements.txt (line 5))\n","  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r requirements.txt (line 6)) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->-r requirements.txt (line 15)) (3.0.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->-r requirements.txt (line 15)) (1.3.0)\n","Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n","Downloading ultralytics-8.3.13-py3-none-any.whl (870 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m870.5/870.5 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ultralytics_thop-2.0.9-py3-none-any.whl (26 kB)\n","Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n","Installing collected packages: smmap, gitdb, ultralytics-thop, thop, gitpython, ultralytics\n","Successfully installed gitdb-4.0.11 gitpython-3.1.43 smmap-5.0.1 thop-0.1.1.post2209072238 ultralytics-8.3.13 ultralytics-thop-2.0.9\n"]}],"source":["%cd yolov5/\n","!pip install -r requirements.txt\n"]},{"cell_type":"markdown","metadata":{"id":"F4TfP7iGITng"},"source":["## Perform object detection using 'yolov5s' model and save detection results\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1AG_uMlBa4aadq9emmiuuY_7r4XOYcxuE"},"id":"cABdHK_oLwUv","outputId":"2bb9e38e-2710-48c5-8e63-76799cbd2811"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["import torch\n","import cv2\n","import os\n","\n","# Load pre-trained YOLOv5 model\n","model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n","\n","# Path to the directory containing the images\n","image_folder = '../Photo'\n","\n","# Output folder for detection results\n","output_folder = 'detection_results/'\n","\n","# Create the output folder if it doesn't exist\n","os.makedirs(output_folder, exist_ok=True)\n","\n","# Loop through the images in the folder and run object detection\n","for img_name in os.listdir(image_folder):\n","    img_path = os.path.join(image_folder, img_name)\n","\n","    # Read the image using OpenCV\n","    img = cv2.imread(img_path)\n","\n","    if img is None:\n","        print(f\"Could not read image {img_name}. Skipping...\")\n","        continue\n","\n","    # Run object detection\n","    results = model(img)\n","    results.show()\n","\n","    # Extract the results as an image (with bounding boxes)\n","    detected_img = results.render()[0]  # YOLOv5's `render` method draws the boxes on the image\n","\n","    # Save the detected image with the same name as the original image\n","    output_path = os.path.join(output_folder, img_name)\n","    cv2.imwrite(output_path, detected_img)\n","\n","    print(f\"Saved detection result for {img_name} to {output_folder}\")\n"]},{"cell_type":"markdown","metadata":{"id":"QrmNwkeTNsel"},"source":["## Save the detection result data of each image in CSV format"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XgzbAuQEkfgi"},"outputs":[],"source":["import pandas as pd\n","import os\n","\n","# Initialize an empty list to store all detection results for each image\n","all_detections = []\n","\n","# Loop through the images in the folder and process the detection results\n","for img_name in os.listdir(image_folder):\n","    img_path = os.path.join(image_folder, img_name)\n","\n","    # Run object detection\n","    results = model(img_path)\n","\n","    # Extract the detection data as a Pandas DataFrame\n","    detections = results.pandas().xyxy[0]  # Pandas DataFrame of detection results\n","\n","    # Extract details into lists\n","    labels = detections['name'].tolist()  # List of object labels\n","    confidences = detections['confidence'].tolist()  # List of confidence scores\n","    xmins = detections['xmin'].tolist()  # List of xmin values\n","    ymins = detections['ymin'].tolist()  # List of ymin values\n","    xmaxs = detections['xmax'].tolist()  # List of xmax values\n","    ymaxs = detections['ymax'].tolist()  # List of ymax values\n","\n","    # Append a single row of data for this image (lists of detections)\n","    all_detections.append({\n","        'image_name': img_name,\n","        'labels': ','.join(labels),  # Convert list to comma-separated string\n","        'confidences': ','.join(map(str, confidences)),  # Convert list of floats to string\n","        'xmins': ','.join(map(str, xmins)),\n","        'ymins': ','.join(map(str, ymins)),\n","        'xmaxs': ','.join(map(str, xmaxs)),\n","        'ymaxs': ','.join(map(str, ymaxs))\n","    })\n","\n","# Convert the list of dictionaries to a DataFrame\n","df_all_detections = pd.DataFrame(all_detections)\n","\n","# Save the DataFrame to a single CSV file\n","df_all_detections.to_csv('detection_results/all_detections_single_row.csv', index=False)\n","\n","print(\"All detections saved to 'detection_results/all_detections_single_row.csv'.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1130,"status":"ok","timestamp":1728977789612,"user":{"displayName":"Wolderufael Kassahun","userId":"05849674619156846485"},"user_tz":-180},"id":"Vbqhyf9Y_DXn","outputId":"a95dfbe0-8a50-4961-dcab-14f386782045"},"outputs":[{"name":"stderr","output_type":"stream","text":["/root/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with amp.autocast(autocast):\n","/root/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with amp.autocast(autocast):\n","/root/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with amp.autocast(autocast):\n","/root/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with amp.autocast(autocast):\n"]},{"name":"stdout","output_type":"stream","text":["Detections for @CheMed123_31.jpg:\n","           name  confidence        xmin        ymin        xmax        ymax\n","0        bottle    0.665459  575.392029  379.652008  607.572815  462.765839\n","1        bottle    0.441411  505.947754  451.101440  543.062988  547.977295\n","2        bottle    0.440981  610.182312  513.144531  638.696594  603.373535\n","3        bottle    0.372860  601.915100  391.862762  631.961853  452.176117\n","4        bottle    0.356146  547.596985  389.668182  579.092834  457.973175\n","5        bottle    0.352985  398.049927  505.606171  442.209106  612.510132\n","6  refrigerator    0.301540  294.992432   47.041260  743.797852  892.147461\n","7        bottle    0.280549  434.289215  537.001404  482.314056  625.838440\n","8        bottle    0.277430  400.934601  287.164368  442.911407  370.231873\n","9        bottle    0.261580  503.835449  588.662354  536.245483  673.241089\n","Detections for @CheMed123_39.jpg:\n","    name  confidence        xmin        ymin        xmax        ymax\n","0  mouse    0.880747  145.529709  171.890564  320.155945  301.116394\n","1  mouse    0.823763  471.925476  483.348938  673.408997  619.613586\n","2  mouse    0.792538  256.898132  372.917328  401.679993  537.010132\n","3  mouse    0.781965    0.694679  331.120941  213.252533  418.961334\n","4  mouse    0.721328  256.759155  249.690247  436.443970  389.598938\n","5  mouse    0.430206  476.323364  297.543396  674.307495  423.586365\n","6  mouse    0.332343  631.800842  576.111389  799.573792  639.660828\n","7  mouse    0.280578  442.572937  148.927032  589.975037  293.880829\n","Detections for @CheMed123_38.jpg:\n","           name  confidence       xmin        ymin        xmax        ymax\n","0  baseball bat    0.341462  52.848755  134.661896  548.361450  442.428223\n","1  baseball bat    0.280543  84.102234  251.078308  591.642578  540.854614\n","Detections for @lobelia4cosmetics_12102.jpg:\n","     name  confidence        xmin        ymin        xmax        ymax\n","0  person    0.854438  386.629028  569.150696  798.967163  1072.49353\n"]},{"name":"stderr","output_type":"stream","text":["/root/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with amp.autocast(autocast):\n","/root/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with amp.autocast(autocast):\n","/root/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with amp.autocast(autocast):\n","/root/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with amp.autocast(autocast):\n"]},{"name":"stdout","output_type":"stream","text":["Detections for @CheMed123_45.jpg:\n","         name  confidence        xmin        ymin        xmax        ymax\n","0  toothbrush    0.323845  362.874542  770.962646  507.755859  917.678223\n","Detections for @CheMed123_19.jpg:\n","     name  confidence         xmin        ymin         xmax        ymax\n","0  person    0.911893    48.459961  387.686096   570.671875  861.487122\n","1  person    0.844647   676.221741  432.538910  1181.538818  883.707886\n","2  person    0.400056  1177.549683   79.024994  1280.000000  852.001831\n","3   chair    0.367656   666.536865  701.023254   710.996582  839.201111\n","4    book    0.271122   730.939392  750.106995   975.868835  951.085876\n","Detections for @lobelia4cosmetics_12090.jpg:\n","Empty DataFrame\n","Columns: [name, confidence, xmin, ymin, xmax, ymax]\n","Index: []\n","Detections for @lobelia4cosmetics_12076.jpg:\n","Empty DataFrame\n","Columns: [name, confidence, xmin, ymin, xmax, ymax]\n","Index: []\n","Detections for @CheMed123_22.jpg:\n","         name  confidence        xmin        ymin        xmax        ymax\n","0  cell phone    0.699048  137.839264  143.148453  588.139526  631.168335\n","1  cell phone    0.362617  268.356140   78.368950  814.016052  418.983154\n","Detections for @lobelia4cosmetics_12113.jpg:\n","Empty DataFrame\n","Columns: [name, confidence, xmin, ymin, xmax, ymax]\n","Index: []\n"]},{"name":"stderr","output_type":"stream","text":["/root/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with amp.autocast(autocast):\n","/root/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with amp.autocast(autocast):\n"]}],"source":["import pandas as pd\n","\n","# Process results to extract bounding box, class labels, and confidence scores\n","for img_name in os.listdir(image_folder):\n","    img_path = os.path.join(image_folder, img_name)\n","\n","    # Run object detection\n","    results = model(img_path)\n","\n","    # Extract data from results\n","    detections = results.pandas().xyxy[0]  # Pandas dataframe of detection results\n","    print(f\"Detections for {img_name}:\")\n","    print(detections[['name', 'confidence', 'xmin', 'ymin', 'xmax', 'ymax']])\n","\n","    # Save detections to CSV file\n","    detections[['name', 'confidence', 'xmin', 'ymin', 'xmax', 'ymax']].to_csv(f'detection_results/{img_name}_detections.csv', index=False)\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1rEQXqrQu7nEJog3dp4-54tOqDendbHse","timestamp":1728976446224}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}